{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langevin Dynamics\n",
    "\n",
    "\n",
    "We will assume that the target distribution $\\rho_{\\rm post}(\\theta|y)$, defined on $R^{N_{\\theta}}$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\rho_{\\rm post}(\\theta|y) \\propto \\exp\\Bigl(-\\Phi(\\theta; y)\\Bigr)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "##  Langevin diffusion\n",
    "Consider the initial value Ito process that acts on a random variable $\\theta_t \\in R^{N_{\\theta}}$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "d\\theta_t = -\\nabla_{\\theta} \\Phi(\\theta_t; y) dt + \\sqrt{2}dW_t\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $W_t \\in R^{N_{\\theta}}$ is a standard Wiener process. Langevin dynamics for sampling uses the property that $\\rho_{\\rm post}(\\theta|y) \\propto \\exp\\Bigl(-\\Phi(\\theta; y)\\Bigr)$ is the stationary distribution of the diffusion process.\n",
    "\n",
    "Assume the random variable at each time $t$ has a probability density $\\theta_t \\sim \\rho_t(\\theta)$. The Fokker-Plank equation representing the evolution of the probability density $\\rho_t(\\theta)$ is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\rho_t(\\theta)}{\\partial t} \n",
    "&= \\nabla_{\\theta} \\bigl[\\rho_t(\\theta) \\nabla_{\\theta} \\Phi(\\theta; y)\\bigr] + \\Delta_{\\theta} \\rho_t(\\theta)\\\\\n",
    "&= \\nabla_{\\theta} \\bigl[\\rho_t(\\theta) \\bigl(\\nabla_{\\theta} \\Phi(\\theta; y) + \\nabla_{\\theta} \\log \\rho_t(\\theta)\\bigr)\\bigr]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Intuitively, \n",
    "$$\\lim_{t \\rightarrow +\\infty} \\log \\rho_t(\\theta) = -\\Phi(\\theta; y) + C$$\n",
    "\n",
    "\n",
    "Moreover, for the $KL$-divergence \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial t}KL\\Bigl[\\rho_{t}(\\theta) \\Vert  \\rho_{\\rm post}(\\theta | y)\\Bigr]\n",
    "&= \\frac{\\partial}{\\partial t} \\int \\rho_{t}(\\theta)  \\log \\frac{\\rho_{t}(\\theta)}{\\rho_{\\rm post}(\\theta | y)} d\\theta \\\\\n",
    "&= \\int \\nabla_{\\theta} \\Bigl[\\rho_t(\\theta) \\bigl(\\nabla_{\\theta} \\Phi(\\theta; y) + \\nabla_{\\theta} \\log \\rho_t(\\theta)\\bigr)\\Bigr] \\Bigl[ \\log \\frac{\\rho_{t}(\\theta)}{\\rho_{\\rm post}(\\theta | y)} + 1 \\Bigr] d\\theta \\\\\n",
    "&= -\\int \\rho_t(\\theta) \\bigl(\\nabla_{\\theta} \\Phi(\\theta; y) + \\nabla_{\\theta} \\log \\rho_t(\\theta)\\bigr)^2 d\\theta \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Therefore, the $KL$-divergence reduces, which leads to the convergence to the posterior probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General initial value Ito process\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
