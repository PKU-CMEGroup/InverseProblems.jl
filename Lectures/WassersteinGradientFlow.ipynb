{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Gradient Flow\n",
    "\n",
    "Let define the KL divergence function on the density space $\\mathcal{P}$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{E}(\\rho) = KL\\Bigl[\\rho \\Big\\Vert  \\rho_{\\rm post}\\Bigr] = \\int\\rho\\log \\frac{\\rho}{\\rho_{\\rm post}} d\\theta\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Its functional derivative is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\delta \\mathcal{E}}{\\delta \\rho} \n",
    "=  \\log \\rho  - \\log \\rho_{\\rm post}  + \\textrm{const.}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let define **Wasserstein metric**\n",
    "\n",
    "$$\n",
    "M(\\rho)^{-1} \\psi = - \\nabla\\cdot \\bigl( \\rho\\nabla_{\\theta}\\psi \\bigr), \\qquad  \\psi \\in T_{\\rho}^{*}\\mathcal{P}\n",
    "$$\n",
    "\n",
    "\n",
    "For the Wasserstein gradient flow of the KL divergence is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\rho_t(\\theta)}{\\partial t} \n",
    "&= - M(\\rho)^{-1}\\frac{\\delta \\mathcal{E}}{\\delta \\rho} =  -\\nabla_{\\theta}\\cdot\\Bigl(\\rho_t \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) \\Bigr)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This is the Fokker-Planck equation of the Langevin dynamics \n",
    "$$\n",
    "d\\theta_t = \\nabla_{\\theta} \\log \\rho_{\\rm post}(\\theta_t) dt + \\sqrt{2}dW_t,\n",
    "$$\n",
    "which can be used for sampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Semigroups\n",
    "\n",
    "The Langevin dynamics $\\{\\theta_t\\}_{t\\geq0}$ is a Markov process, which can be studied as a semigroup $P = \\{P_t\\}_{t\\geq 0}$\n",
    "\n",
    "$$P_t f(\\theta) = \\mathbb{E}[f(\\theta_t) | \\theta_0 = \\theta] := \\int f(\\theta') p_t(\\theta, \\theta') d\\theta'$$\n",
    "\n",
    "Here $\\rho_t$ is the associated probability kernel. By Jensen's inequality, for every convex function $\\phi$, $P_t(\\phi(f)) \\geq \\phi(P_t f)$.\n",
    "\n",
    "By duality, those semigroups $\\{P_t\\}_{t\\geq 0}$ also act on measures $\\nu$\n",
    "$$ \\int P_t f d\\nu_0 = \\int f d \\nu_t \\qquad d\\nu_t := dP_t^{*} \\nu_0 $$\n",
    "The invariant distribution $\\mu$ satisfies \n",
    "$$ \\int P_t f d\\mu = \\int f d \\mu \\qquad d\\nu_t := dP_t^{*} \\nu_0. $$\n",
    "\n",
    "The Ergodicity is related to that $P_t f(x)$ converges to $\\int fd\\mu$. This indicates that for the Langevin dynamics, the law of $\\theta_t$ will converge to the invariant probability measure $\\mu$ as $t\\rightarrow \\infty$.\n",
    "\n",
    "\n",
    "Its **infinitesimal generator** is defined as \n",
    "$$\\partial_t P_t = LP_t = P_t L$$\n",
    "For the Langevin dynamics, \n",
    "\\begin{align} \n",
    "\\partial_t \\int P_t f d\\nu_0 \n",
    "&\n",
    "= \\int f \\partial_t\\rho_t d \\theta  = -\\int f \\nabla_{\\theta}\\cdot\\Bigl(\\rho_t \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) \\Bigr) d \\theta \n",
    "= \\int \\nabla_{\\theta} f \\cdot\\Bigl(\\rho_t \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) \\Bigr) d \\theta \\\\\n",
    "&\n",
    "= \\int \\nabla_{\\theta}\\nabla_{\\theta} f  + \\nabla_{\\theta}\\log \\rho_{\\rm post} \\nabla_{\\theta} f \\\\\n",
    "\\end{align}\n",
    "Therefore, we have\n",
    "$$Lf = \\nabla_{\\theta}\\nabla_{\\theta} f  + \\nabla_{\\theta} \\log \\rho_{\\rm post} \\cdot \\nabla_{\\theta} f $$\n",
    "\n",
    "For the invariant distribution, we have \n",
    "$$\\int Lf d\\mu = 0$$\n",
    "\n",
    "\n",
    "The Markov semigroup $P$ is said to be symmetric with respect to the invariant measure $\\mu$, or $\\mu$ is reversible for $P$, if for all functions $f$ and $g$\n",
    "$$\\int f P_t g d\\mu = \\int g P_t f d\\mu $$\n",
    "That also indicates that $p_t(x,dy)\\mu(dx) = p_t(y,dx)\\mu(dy)$ and $\\int f L g d\\mu = \\int gL f d\\mu $ ($L$ is self-adjoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local property\n",
    "\n",
    "## Carre du Champ Operators\n",
    "\n",
    "\n",
    "The bilinear map \n",
    "$$\\Gamma(f,g) = \\frac{1}{2}[L(fg) - fLg - gLf]$$\n",
    "In the limit of $P_t(f^2) \\geq (P_t f)^2$, we have $\\Gamma(f,f)\\geq 0$.\n",
    "\n",
    "For the Langevin dynamics, it becomes\n",
    "$$\\Gamma(f,g) = \\nabla_{\\theta}f \\cdot \\nabla_{\\theta}g$$\n",
    "When the Markov semigroup is symmetric, we have\n",
    "$$\\int \\Gamma(f,g)d\\mu = -\\int f Lg d\\mu$$\n",
    "And hence, $-L$ is positive semidefinite.\n",
    "\n",
    "## Iterated Carre du Champ Operators\n",
    "Replacing the product operation by $\\Gamma$ leads to \n",
    "$$\\Gamma_2(f,g) = \\frac{1}{2}[L\\Gamma(f,g) - \\Gamma(f, Lg) - \\Gamma(g,Lf)]$$\n",
    "For the Langevin dynamics, it becomes\n",
    "$$\\Gamma_2(f,g) = \\nabla_{\\theta}\\nabla_{\\theta}f:\\nabla_{\\theta}\\nabla_{\\theta}g - \\nabla_{\\theta}f^T \\nabla_{\\theta}\\nabla_{\\theta}\\log\\rho_{\\rm post} \\nabla_{\\theta}g$$\n",
    "\n",
    "\n",
    "## Curvature-dimension condition\n",
    "At the core of functional inequality is the curvature-dimension condition $\\textrm{CD}(\\rho, n)$, for $\\rho\\in\\mathbb{R}$ and $n\\in[1,\\infty]$\n",
    "\n",
    "$$\\Gamma_2(f) \\geq \\rho \\Gamma(f) + \\frac{1}{n}(Lf)^2$$\n",
    "($\\mu$-almost everywhere).\n",
    "Consider curvature-dimension condition $\\textrm{CD}(\\rho,\\infty)$, the determinant of $\\Gamma_2(g) \\geq \\rho \\Gamma(g)$ for $g=af_1 + b f_2 f_3$ with arbitrary $a$ and $b$ implies that \n",
    "\n",
    "$$4\\Gamma(f)[\\Gamma_2(f) - \\rho\\Gamma(f)] \\geq \\Gamma(\\Gamma(f))$$\n",
    "which is referred as the reinforced $\\textrm{CD}(\\rho,\\infty)$ inequality.\n",
    "\n",
    "## Dirichlet form\n",
    "For reversible measure $\\mu$, the Dirichlet form is\n",
    "$$\\mathcal{E}(f,g) = \\int \\Gamma(f,g)d\\mu = -\\int fLg d\\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient bound\n",
    "\n",
    "For reversible measure $\\mu$, we have that $\\mathrm{CD}(\\rho,\\infty)$ leads to \n",
    "\n",
    "$$\\Gamma(P_t f) \\leq e^{-2 \\rho t} P_t(\\Gamma(f))\\quad \\textrm{and} \\quad \\sqrt{\\Gamma(P_t f)} \\leq e^{-\\rho t} P_t(\\sqrt{\\Gamma(f)})$$\n",
    "\n",
    "\n",
    "**Formal proof**. For the first ineqaulity, let denote \n",
    "\n",
    "$$\\Lambda(s) = P_s(\\Gamma(P_{t-s}f)) \\qquad s\\in [0,t]$$\n",
    "\n",
    "Then we have $\\Lambda(0) = \\Gamma(P_{t}f)$ and $\\Lambda(t) = P_t(\\Gamma(f))$. Next we will prove that $\\Lambda' \\geq 2\\rho \\Lambda$. We have \n",
    "\n",
    "$$\\Lambda'(s) = LP_s(\\Gamma(P_{t-s}f)) - 2P_s\\Gamma(P_{t-s}f, LP_{t-s}f)  $$\n",
    "\n",
    "Rewriting this identity with $g = P_{t-s}f$,\n",
    "\n",
    "$$\\Lambda'(s) = LP_s(\\Gamma(g)) - 2P_s\\Gamma(g, Lg) = P_s(L\\Gamma(g) - 2\\Gamma(g, Lg)) = 2P_s(\\Gamma_2(g))  \\geq 2P_s(\\rho\\Gamma(g)) =  2\\rho \\Lambda(s)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second ineqaulity, let denote \n",
    "\n",
    "$$\\Lambda(s) = P_s(\\sqrt{\\Gamma(P_{t-s}f)}) \\qquad s\\in [0,t]$$\n",
    "\n",
    "Then we have $\\Lambda(0) = \\sqrt{\\Gamma(P_{t}f)}$ and $\\Lambda(t) = P_t(\\sqrt{\\Gamma(f)})$. Next we will prove that $\\Lambda' \\geq \\rho \\Lambda$. We have \n",
    "\n",
    "\\begin{align}\n",
    "\\Lambda'(s) \n",
    "&= LP_s(\\sqrt{\\Gamma(P_{t-s}f)}) - P_s\\Gamma(P_{t-s}f)^{-1/2}\\Gamma(P_{t-s}f, LP_{t-s}f) \\\\\n",
    "&= P_s\\Bigl( \\Gamma(P_{t-s}f)^{-1/2} \\bigl( \\Gamma_2(P_{t-s}f) - \\frac{\\Gamma(\\Gamma(P_{t-s}f))}{4\\Gamma(P_{t-s}f)}\\bigr)\\Bigr)\n",
    "\\end{align}\n",
    "\n",
    "Rewriting this identity with $g = P_{t-s}f$,\n",
    "\n",
    "$$\\Lambda'(s) = P_s\\Bigl( \\Gamma(g)^{-1/2} \\bigl( \\Gamma_2(g) - \\frac{\\Gamma(\\Gamma(g))}{4\\Gamma(g)}\\bigr)\\Bigr)\\geq \\rho P_s(\\sqrt{g})$$\n",
    "\n",
    "here we used the reinforced $\\textrm{CD}(\\rho, \\infty)$ inequality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergodicity\n",
    "\n",
    "In probability theory, ergodic properties usually relate to the long time behavior. In the context of Markov processes $\\{\\theta_t ; t \\geq 0\\}$, it is in general expected that quantities such as\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lim_{t \\rightarrow \\infty} \\frac{1}{t}\\int_0^t f(\\theta_s) ds = \\int f d\\mu\n",
    "\\end{align*}\n",
    "$$\n",
    "converge almost surely. In a less ambitious approach, ergodicity relates to that $P_t f(\\theta)$ converges to $\\int f d\\mu$ for any $\\theta$. Since $P_t = e^{tL}$, formally, $P_t f$ converges in $L_2(\\mu)$ to the projection of $f$ on the space of functions with satisfies $Lf=0$. Then $L$ is ergodic if $Lf = 0$ leads to that $f$ is constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logconcave density \n",
    "The logconcave distribution satisfies that $d\\mu = \\rho_{\\rm post}(\\theta) d\\theta \\propto e^{-W} d\\theta$ and $\\nabla\\nabla W \\geq \\rho I$.  In this section, we study different inequalities related to logconcave invariant distribution. These inequalities underpin the convergence of the Langevin dynamics for sampling.\n",
    "For the Langevin dynamics, the invariant distribution satisfies $CD(\\rho, \\infty)$ condition:\n",
    "\\begin{align*}\n",
    "\\Gamma_2(f,f) = \\nabla_{\\theta}\\nabla_{\\theta}f:\\nabla_{\\theta}\\nabla_{\\theta}f - \\nabla_{\\theta}f^T \\nabla_{\\theta}\\nabla_{\\theta}\\log\\rho_{\\rm post} \\nabla_{\\theta}f \\geq\n",
    "\\nabla_{\\theta}f^T \\nabla_{\\theta}\\nabla_{\\theta}W \\nabla_{\\theta}f \\geq  \\rho \\nabla_{\\theta}^T f \\nabla_{\\theta} f\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "## Poincare Inequalities\n",
    "Let define the variance of a function f in $L_2(\\mu)$ as \n",
    "\\begin{align*}\n",
    "Var_{\\mu}(f) = \\int f^2 d\\mu - \\Bigl(\\int f d\\mu\\Bigr)^2\n",
    "\\end{align*}\n",
    "A Markov Process with invariant measure $\\mu$ is said to satisfy a Poincare, or spectral gap, inequality with constant $C>0$, if \n",
    "\\begin{align*}\n",
    "Var_{\\mu}(f) \\leq C\\mathcal{E}(f)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "For the Langevin dynamics, when the invariant distribution satisfies $CD(\\rho, \\infty)$, \n",
    "it leads to  \n",
    "\n",
    "$$\\Gamma(P_t f) \\leq e^{-2 \\rho t} P_t(\\Gamma(f))$$\n",
    "\n",
    "Consider $\\Lambda(s) = P_s\\bigl((P_{t-s}f)^2\\bigr)$, $s \\in [0,t]$, we have\n",
    "\n",
    "$$\\Lambda(s)' =  LP_s\\bigl((P_{t-s}f)^2\\bigr) - P_s\\bigl(2P_{t-s}f L P_{t-s}\\Gamma f)\\bigr) = 2P_s(\\Gamma(P_{t-s} \\Gamma f))$$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$ P_t\\bigl( f^2\\bigr) - (P_tf)^2 = \\Lambda(t) - \\Lambda(0) =  \\int_0^t \\Lambda(s)' ds = \\int_0^t 2P_s(\\Gamma(P_{t-s}f)) ds  \\leq \\int_0^t 2P_s(e^{-2 \\rho (t-s)} P_{t-s}f) ds  = \\frac{1 - e^{-2\\rho t}}{\\rho} P_t(\\Gamma f)$$\n",
    "\n",
    "\n",
    "Using ergodicity and leting $t \\rightarrow \\infty$ lead to the Poincare inequality\n",
    "\n",
    "$$ \\int  f^2 d\\mu - \\Bigl(\\int f d\\mu \\Bigr)^2  = \\frac{1 }{\\rho} \\int \\Gamma f d\\mu = \\frac{1 }{\\rho} \\int \\nabla f \\nabla f d\\mu $$\n",
    "\n",
    "\n",
    "## Log Sobolev Inequalities\n",
    "\n",
    "Let define the entropy of a function f with $\\int f \\lvert \\log f \\rvert d \\mu < \\infty$ as \n",
    "\n",
    "\\begin{align*}\n",
    "Ent_{\\mu}(f) = \\int f \\log f d\\mu - \\int f d\\nu  \\log \\Bigl( \\int f d\\mu \\Bigr)\n",
    "\\end{align*}\n",
    "\n",
    "A Markov Process with invariant measure $\\mu$ is said to satisfy a Poincare, or spectral gap, inequality with constant $C>0$, if \n",
    "\n",
    "\\begin{align*}\n",
    "Ent_{\\mu}(f) \\leq 2C\\int \\frac{\\Gamma(f)}{f} d\\mu\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "For the Langevin dynamics, when the invariant distribution satisfies $CD(\\rho, \\infty)$, \n",
    "it leads to  \n",
    "\n",
    "$$\\sqrt{\\Gamma(P_t f)} \\leq e^{-\\rho t} P_t(\\sqrt{\\Gamma(f)})$$\n",
    "\n",
    "Consider $\\Lambda(s) = P_s\\bigl(\\psi(P_{t-s}f)\\bigr)$, $s \\in [0,t]$, with $\\psi(r) = r\\log r$, we have\n",
    "\n",
    "$$\\Lambda(s)' =  LP_s\\bigl(\\psi(P_{t-s}f)\\bigr) - P_s\\bigl(\\psi'(P_{t-s}f) L P_{t-s} f)\\bigr) = P_s(\\frac{\\Gamma(P_{t-s}f)}{P_{t-s}f}) \\leq e^{-2\\rho (t-s)} P_s(\\frac{\\bigl(P_{t-s}\\sqrt{\\Gamma(f)}\\bigr)^2}{P_{t-s}f}) \\leq e^{-2\\rho (t-s)} P_s(P_{t-s} \\frac{\\Gamma(f)}{f}) $$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$ P_t\\bigl( \\psi(f) \\bigr) - \\psi(P_tf) = \\Lambda(t) - \\Lambda(0) =  \\int_0^t \\Lambda(s)' ds = \\int_0^t e^{-2\\rho (t-s)} P_t(\\frac{\\Gamma(f)}{f}) ds    = \\frac{1 - e^{-2\\rho t}}{2\\rho} P_t(\\frac{\\Gamma(f)}{f})$$\n",
    "\n",
    "\n",
    "Using ergodicity and leting $t \\rightarrow \\infty$ lead to the Poincare inequality\n",
    "\n",
    "\\begin{align*}\n",
    "Ent_{\\mu}(f) \\leq \\frac{1}{2\\rho}\\int \\frac{\\Gamma(f)}{f} d\\mu\n",
    "\\end{align*}\n",
    "\n",
    "When $d\\mu$ satisfies the log Sobolev inequality with constant $C$, $h\\,d\\mu$ with $\\frac{1}{b} \\leq h \\leq b$ satisfies the log Sobolev inequality with constant $Cb^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logconcave Sampling\n",
    "\n",
    "For the Wasserstein gradient flow of the KL divergence is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\rho_t(\\theta)}{\\partial t} \n",
    "&=  -\\nabla_{\\theta}\\cdot\\Bigl(\\rho_t \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) \\Bigr)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Assume $-\\nabla_{\\theta}\\nabla_{\\theta}\\rho_{\\rm post} \\geq \\rho $, the KL divergence satisfies\n",
    "\n",
    "\\begin{align*}\n",
    "-\\frac{\\partial KL[\\rho_t \\Vert \\rho_{\\rm post}]}{\\partial t} = \\int \\rho_t \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) \\cdot \\nabla_{\\theta}\\bigl(\\log \\rho_{\\rm post} - \\log \\rho_{t} \\bigr) = \\int \\rho_{\\rm post }\\frac{\\nabla_{\\theta} \\frac{\\rho_t}{\\rho_{\\rm post}} \\nabla_{\\theta} \\frac{\\rho_t}{\\rho_{\\rm post}}}{\\frac{\\rho_t}{\\rho_{\\rm post}}}  \\geq 2\\rho Ent_{\\mu}(\\frac{\\rho_t}{\\rho_{\\rm post}}) = 2\\rho KL[\\rho_t \\Vert \\rho_{\\rm post}]\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, $KL[\\rho_t \\Vert \\rho_{\\rm post}] \\leq e^{-2\\rho t} KL[\\rho_0 \\Vert \\rho_{\\rm post}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. [Analysis and Geometry of Markov Diffusion Operators](https://link.springer.com/book/10.1007/978-3-319-00227-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
