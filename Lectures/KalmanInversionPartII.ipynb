{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter on the Stationary Dynamics\n",
    "\n",
    "The inverse problem \n",
    "\n",
    "$$y = \\mathcal{G}(\\theta) + \\eta$$\n",
    "\n",
    "can be solved by first introducing a (mean-field) stochastic dynamical system in which the parameter-to-data map is embedded and then employing techniques from nonlinear Kalman filtering.\n",
    "\n",
    "Consider a family of stochastic dynamical systems\n",
    "\n",
    "$$\\begin{align}\n",
    "  &\\textrm{evolution:}    &&\\theta_{n+1} = r + \\alpha (\\theta_{n}  - r) +  \\omega_{n+1}, &&\\omega_{n+1} \\sim \\mathcal{N}(0,\\Sigma_{\\omega}),\\\\\n",
    "  &\\textrm{observation:}  &&x_{n+1} = \\mathcal{F}(\\theta_{n+1}) + \\nu_{n+1}, &&\\nu_{n+1} \\sim \\mathcal{N}(0,\\Sigma_{\\nu}).\n",
    "\\end{align}$$\n",
    "\n",
    "Then different Kalman filters can be employed on these stochastic dynamical systems, which leads to different Kalman inversion algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Gaussian Approximation Algorithm\n",
    "\n",
    "Let denote $Y_n=\\{x_{\\ell}\\}_{\\ell=1}^{n}$, then Kalman filter process aims to approximate $\\rho_n(\\theta)$, the probability density function of the conditional distribution of $\\theta_n|Y_n$. \n",
    "In the predition step, we predict $\\rho_n \n",
    "\\mapsto \\hat{\\rho}_{n+1}$, where $\\hat{\\rho}_{n+1}$ is the probability density function of the distribution\n",
    "of $\\theta_{n+1}|Y_n$; in the analysis step, we update \n",
    "$\\hat{\\rho}_{n+1} \\mapsto \\rho_{n+1}$, \n",
    "\n",
    "This conceptual algorithm maps Gaussians into Gaussians.\n",
    "Re refer to it henceforth as the Gaussian Approximation Algorithm.\n",
    "\n",
    "## Prediction Step\n",
    "Assume that $\\rho_n \\approx \\mathcal{N}(m_n,C_n)$. \n",
    "Note that, under the linear evolution,\n",
    "$\\hat{\\rho}_{n+1}$ is also Gaussian with mean and covariance\n",
    "\n",
    "$$ \\hat{m}_{n+1} = \\mathbb{E}[\\theta_{n+1}|Y_n] =  r + \\alpha (m_n  - r) \\qquad \n",
    "\\hat{C}_{n+1} = \\mathrm{Cov}[\\theta_{n+1}|Y_n] = \\alpha^2C_{n} + \\Sigma_{\\omega}$$\n",
    "\n",
    "## Analysis Step\n",
    "The algorithm proceeds by introducing the joint distribution\n",
    "of $\\theta_{n+1}, y_{n+1}|Y_n$,  projecting this onto a Gaussian by computing\n",
    "its mean and covariance, and then conditioning this Gaussian to obtain\n",
    "a Gaussian approximation  $\\mathcal{N}(m_{n+1},C_{n+1})$ to $\\mu_{n+1}.$\n",
    "\n",
    "In the analysis step, we assume that the joint distribution of  $\\{\\theta_{n+1}, y_{n+1}\\}|Y_{n}$ can be approximated by a Gaussian distribution\n",
    "\n",
    "$$\\begin{equation}\n",
    "     \\mathcal{N}\\Bigl(\n",
    "    \\begin{bmatrix}\n",
    "    \\hat{m}_{n+1}\\\\\n",
    "    \\hat{x}_{n+1}\n",
    "    \\end{bmatrix}, \n",
    "    \\begin{bmatrix}\n",
    "   \\hat{C}_{n+1} & \\hat{C}_{n+1}^{\\theta x}\\\\\n",
    "    {\\hat{C}_{n+1}^{\\theta x}}{}^{T} & \\hat{C}_{n+1}^{xx}\n",
    "    \\end{bmatrix}\n",
    "    \\Bigr).\n",
    "\\end{equation}$$\n",
    "\n",
    "Then, with $\\mathbb{E}$ denoting expectation with respect to \n",
    "$\\theta_{n+1}|Y_n \\sim \\mathcal{N}( \\hat{m}_{n+1},\\hat{C}_{n+1})$, \n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\hat{x}_{n+1} =     & \\mathbb{E}[\\mathcal{F}(\\theta_{n+1})|Y_n], \\\\\n",
    "    \\hat{C}_{n+1}^{\\theta x} =     &  \\mathrm{Cov}[\\theta_{n+1}, \\mathcal{F}(\\theta_{n+1})|Y_n],\\\\\n",
    "    \\hat{C}_{n+1}^{xx} = &  \\mathrm{Cov}[\\mathcal{F}(\\theta_{n+1})|Y_n] + \\Sigma_{\\nu}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Conditioning the Gaussian to find $\\theta_{n+1}|\\{Y_n,x_{n+1}\\}=\\theta_{n+1}|Y_{n+1}$ gives the following\n",
    "expressions for the mean $m_{n+1}$ and covariance $C_{n+1}$ of the\n",
    "approximation to $\\mu_{n+1}:$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\label{eq:KF_analysis}\n",
    "    \\begin{split}\n",
    "        m_{n+1} &= \\hat{m}_{n+1} + \\hat{C}_{n+1}^{\\theta x} (\\hat{C}_{n+1}^{xx})^{-1} (x_{n+1} - \\hat{x}_{n+1}),\\\\\n",
    "        C_{n+1} &= \\hat{C}_{n+1} - \\hat{C}_{n+1}^{\\theta x}(\\hat{C}_{n+1}^{xx})^{-1} {\\hat{C}_{n+1}^{\\theta x}}{}^{T}.\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "These equations establish a conceptual description of the Kalman filter process, however, when $\\mathcal{G}$ is nonlinear, to evaluate these integrals,\n",
    "$\\hat{x}_{n+1}$, $\\hat{C}_{n+1}^{\\theta x}$ and $\\hat{C}_{n+1}^{xx}$, different nonlinear Kalman filters are required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unscented Kalman Inversion\n",
    "\n",
    "When the [unscented Kalman filter](KalmanFilter.ipynb) is applied, the conceptual Gaussian approximation algorithm becomes \n",
    "\n",
    "* Prediction step :\n",
    "\n",
    "    $$\\begin{align*}\n",
    "    \\hat{m}_{n+1} = & r+\\alpha(m_n-r)\\\\\n",
    "    \\hat{C}_{n+1} = & \\alpha^2 C_{n} + \\Sigma_{\\omega}\n",
    "    \\end{align*}$$\n",
    "    \n",
    "* Generate sigma points :\n",
    "    \n",
    "    $$\\begin{align*}\n",
    "    &\\hat{\\theta}_{n+1}^0 = \\hat{m}_{n+1} \\\\\n",
    "    &\\hat{\\theta}_{n+1}^j = \\hat{m}_{n+1} + c_j [\\sqrt{\\hat{C}_{n+1}}]_j \\quad (1\\leq j\\leq N_\\theta)\\\\ \n",
    "    &\\hat{\\theta}_{n+1}^{j+N_\\theta} = \\hat{m}_{n+1} - c_j [\\sqrt{\\hat{C}_{n+1}}]_j\\quad (1\\leq j\\leq N_\\theta)\n",
    "    \\end{align*}$$\n",
    "    \n",
    "*  Analysis step :\n",
    "    \n",
    "   $$\n",
    "   \\begin{align*}\n",
    "        &\\hat{x}^j_{n+1} = \\mathcal{F}(\\hat{\\theta}^j_{n+1}) \\qquad \\hat{x}_{n+1} = \\hat{x}^0_{n+1}\\\\\n",
    "         &\\hat{C}^{\\theta x}_{n+1} = \\sum_{j=1}^{2N_\\theta}W_j^{c}\n",
    "        (\\hat{\\theta}^j_{n+1} - \\hat{m}_{n+1} )(\\hat{x}^j_{n+1} - \\hat{x}_{n+1})^T \\\\\n",
    "        &\\hat{C}^{xx}_{n+1} = \\sum_{j=1}^{2N_\\theta}W_j^{c}\n",
    "        (\\hat{x}^j_{n+1} - \\hat{y}_{n+1} )(\\hat{x}^j_{n+1} - \\hat{x}_{n+1})^T + \\Sigma_{\\nu}\\\\\n",
    "        &m_{n+1} = \\hat{m}_{n+1} + \\hat{C}^{\\theta x}_{n+1}(\\hat{C}^{xx}_{n+1})^{-1}(x - \\hat{x}_{n+1})\\\\\n",
    "        &C_{n+1} = \\hat{C}_{n+1} - \\hat{C}^{\\theta x}_{n+1}(\\hat{C}^{xx}_{n+1})^{-1}{\\hat{C}^{\\theta x}_{n+1}}{}^{T}\\\\\n",
    "    \\end{align*}\n",
    "    $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Ensemble Kalman Inversion\n",
    "\n",
    "When the [stochastic ensemble Kalman filter](Kalman.ipynb) is applied, the conceptual Gaussian approximation algorithm becomes \n",
    "\n",
    "* Prediction step :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\alpha\\theta_{n}^{j}+ (1-\\alpha)r  + \\omega_{n+1}^{j},\\\\ \n",
    "\\hat{m}_{n+1} &= \\frac{1}{J}\\sum_{j=1}^{J}\\hat{\\theta}_{n+1}^{j}\n",
    "\\end{align*}\n",
    "$$\n",
    "    \n",
    "    \n",
    "*  Analysis step :\n",
    "    \n",
    "   $$\n",
    "   \\begin{align*}\n",
    "         &\\hat{x}_{n+1}^{j} = \\mathcal{F}(\\hat{\\theta}_{n+1}^{j})  \\qquad \\hat{x}_{n+1} = \\frac{1}{J}\\sum_{j=1}^{J}\\hat{x}_{n+1}^{j},\\\\\n",
    "         %\n",
    "        &\\hat{C}_{n+1}^{\\theta x} = \\frac{1}{J-1}\\sum_{j=1}^{J}(\\hat{\\theta}_{n+1}^{j} - \\hat{m}_{n+1})(\\hat{x}_{n+1}^{j} - \\hat{x}_{n+1})^T,  \\\\\n",
    "                      %\n",
    "        &\\hat{C}_{n+1}^{xx} = \\frac{1}{J-1}\\sum_{j=1}^{J}(\\hat{x}_{n+1}^{j} - \\hat{x}_{n+1})(\\hat{x}_{n+1}^{j} - \\hat{x}_{n+1})^T +\\Sigma_{\\nu}, \\\\\n",
    "                      %\n",
    "        &\\theta_{n+1}^{j} = \\hat{\\theta}_{n+1}^{j} + \\hat{C}_{n+1}^{\\theta x}\\left(\\hat{C}_{n+1}^{xx}\\right)^{-1}(x - \\hat{x}_{n+1}^{j} - \\nu_{n+1}^{j}),\\\\\n",
    "                      %\n",
    "        &m_{n+1} = \\frac{1}{J} \\sum_{j=1}^{J} \\theta_{n+1}^{j}.\\\\ \n",
    "    \\end{align*}\n",
    "    $$\n",
    "\n",
    "\n",
    "**Remark**\n",
    "When $\\Sigma_{\\omega} = \\gamma C_n$, the prediction step can be treated deterministically, as follows,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{m}_{n+1} &= r + \\alpha(m_n - r) \\\\\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\hat{m}_{n+1} + \\sqrt{\\alpha^2 + \\gamma} (\\theta_n^{j} - m_n)\\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Remark**\n",
    "As a precursor to understanding the adjustment and transform filters which\n",
    "follow this lecture, we need to point out that \n",
    "due to the stochastic treatment in the analysis step, Stochastic Ensemble Kalman Inversion does not exactly replicate the covariance\n",
    "update equation.\n",
    "To this end,\n",
    "denote  the matrix square roots $\\hat{Z}_{n+1},\\, Z_{n+1} \\in \\mathbb{R}^{N_{\\theta}\\times J}$ of $\\hat{C}_{n+1},\\,C_{n+1}$ and $\\hat{\\mathcal{Y}}_{n+1}$ as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{Z}_{n+1} &= \\frac{1}{\\sqrt{J-1}}\\Big(\\hat{\\theta}_{n+1}^{1} - \\hat{m}_{n+1}\\quad \\hat{\\theta}_{n+1}^{2} - \\hat{m}_{n+1}\\quad...\\quad\\hat{\\theta}_{n+1}^{J} - \\hat{m}_{n+1} \\Big),\\\\\n",
    "    Z_{n+1} &= \\frac{1}{\\sqrt{J-1}}\\Big(\\theta_{n+1}^{1} - m_{n+1}\\quad \\theta_{n+1}^{2} - m_{n+1}\\quad...\\quad\\theta_{n+1}^{J} - m_{n+1} \\Big),\\\\\n",
    "    \\hat{\\mathcal{Y}}_{n+1} &= \\frac{1}{\\sqrt{J-1}}\\Big(\\hat{x}_{n+1}^{1} - \\hat{x}_{n+1}\\quad \\hat{x}_{n+1}^{2} - \\hat{x}_{n+1}\\quad...\\quad\\hat{x}_{n+1}^{J} - \\hat{x}_{n+1} \\Big).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then the covariance update equation does not hold exactly:\n",
    "$$\n",
    "\\begin{align*}\n",
    "        \\hat{C}_{n+1} - \\hat{C}_{n+1}^{\\theta x}(\\hat{C}_{n+1}^{xx})^{-1} {\\hat{C}_{n+1}^{\\theta x}}{}^{T} &= \\hat{Z}_{n+1}\\hat{Z}_{n+1}^T - \\hat{Z}_{n+1}\\hat{\\mathcal{Y}}_{n+1}^T (\\hat{\\mathcal{Y}}_{n+1}\\hat{\\mathcal{Y}}_{n+1}^T + \\Sigma_{\\nu,n+1})^{-1}\\hat{\\mathcal{Y}}_{n+1}\\hat{Z}_{n+1}^T \\\\\n",
    "                &\\neq Z_{n+1} Z_{n+1}^T = C_{n+1}.\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Adjustment Kalman Inversion\n",
    "\n",
    "When the ensemble adjustment Kalman filter is applied, the conceptual Gaussian approximation algorithm becomes \n",
    "\n",
    "* Prediction step :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\alpha\\theta_{n}^{j}+ (1-\\alpha)r_0  + \\omega_{n+1}^{j},\\\\ \n",
    "\\hat{m}_{n+1} &= \\frac{1}{J}\\sum_{j=1}^{J}\\hat{\\theta}_{n+1}^{j}\n",
    "\\end{align*}\n",
    "$$\n",
    "    \n",
    "    \n",
    "*  Analysis step :\n",
    "    \n",
    "   $$\n",
    "   \\begin{align*}\n",
    "         &m_{n+1} = \\hat{m}_{n+1} + \\hat{C}_{n+1}^{\\theta x}\\left(\\hat{C}_{n+1}^{xx}\\right)^{-1}(x - \\hat{x}_{n+1})\\\\\n",
    "                      %\n",
    "        &\\theta_{n+1}^{j} = m_{n+1} + A(\\hat{\\theta}_{n+1}^{j} - \\hat{m}_{n+1}) \n",
    "    \\end{align*}\n",
    "    $$\n",
    "\n",
    "where $A = P \\hat{D}^{\\frac{1}{2}} U D^{\\frac{1}{2}}\\hat{D}^{-\\frac{1}{2}}P^T $ with \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "   \\textrm{SVD :}     \\quad       &\\hat{Z}_{n+1} =  P \\hat{D}^{\\frac{1}{2}} V^T,\\\\\n",
    "   \\textrm{SVD :}     \\quad      &V^T\\Big(\\mathbb{I} + \\hat{\\mathcal{Y}}_{n+1}^T \\Sigma_{\\nu,n+1}^{-1}  \\hat{\\mathcal{Y}}_{n+1}\\Big)^{-1} V = U D U^T,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where both $\\hat{D}$ and $D$ are non-singular diagonal matrices, with dimensionality rank($\\hat{Z}_{n+1}$), and $\\hat{Z}_{n+1}$ and $\\hat{\\mathcal{Y}}_{n+1}$ are defined before.\n",
    "\n",
    "**Remark**\n",
    "When $\\Sigma_{\\omega} = \\gamma C_n$, the prediction step can be treated deterministically, as follows,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{m}_{n+1} &= r + \\alpha(m_n - r) \\\\\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\hat{m}_{n+1} + \\sqrt{\\alpha^2 + \\gamma} (\\theta_n^{j} - m_n)\\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Transform Kalman Inversion\n",
    "\n",
    "When the ensemble adjustment Kalman filter is applied, the conceptual Gaussian approximation algorithm becomes \n",
    "\n",
    "* Prediction step :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\alpha\\theta_{n}^{j}+ (1-\\alpha)r_0  + \\omega_{n+1}^{j},\\\\ \n",
    "\\hat{m}_{n+1} &= \\frac{1}{J}\\sum_{j=1}^{J}\\hat{\\theta}_{n+1}^{j}\n",
    "\\end{align*}\n",
    "$$\n",
    "    \n",
    "    \n",
    "*  Analysis step :\n",
    "    \n",
    "   $$\n",
    "   \\begin{align*}\n",
    "         &m_{n+1} = \\hat{m}_{n+1} + \\hat{C}_{n+1}^{\\theta x}\\left(\\hat{C}_{n+1}^{xx}\\right)^{-1}(x - \\hat{x}_{n+1})\\\\\n",
    "                      %\n",
    "        &Z_{n+1} = \\hat{Z}_{n+1} T\n",
    "    \\end{align*}\n",
    "    $$\n",
    "\n",
    "where $T = P(\\Gamma + I)^{-\\frac{1}{2}}P^T$, with \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textrm{SVD:} \\quad \\hat{\\mathcal{Y}}_{n+1} \\Sigma_{\\nu,n+1}^{-1} \\hat{\\mathcal{Y}}_{n+1} = P\\Gamma P^T.\n",
    "\\end{align*}\n",
    "$$\n",
    "**Remark**\n",
    "When $\\Sigma_{\\omega} = \\gamma C_n$, the prediction step can be treated deterministically, as follows,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{m}_{n+1} &= r + \\alpha(m_n - r) \\\\\n",
    "\\hat{\\theta}_{n+1}^{j} &= \\hat{m}_{n+1} + \\sqrt{\\alpha^2 + \\gamma} (\\theta_n^{j} - m_n)\\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
